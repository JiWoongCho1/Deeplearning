{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8a61a3",
   "metadata": {},
   "source": [
    "# 손동작 분류 경진대회\n",
    "\n",
    "**https://dacon.io/competitions/official/235876/codeshare/4673?page=1&dtype=recent 를 카피**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec6d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fde23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5efa8109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2335, 34)\n",
      "(9343, 33)\n",
      "   id   sensor_1  sensor_2   sensor_3   sensor_4   sensor_5   sensor_6  \\\n",
      "0   1  -6.149463 -0.929714   9.058368  -7.017854  -2.958471   0.179233   \n",
      "1   2  -2.238836 -1.003511   5.098079 -10.880357  -0.804562  -2.992123   \n",
      "2   3  19.087934 -2.092514   0.946750 -21.831788   9.119235  17.853587   \n",
      "3   4  -2.211629 -1.930904  21.888406  -3.067560  -0.240634   2.985056   \n",
      "4   5   3.953852  2.964892 -36.044802   0.899838  26.930210  11.004409   \n",
      "\n",
      "    sensor_7   sensor_8   sensor_9  ...  sensor_24  sensor_25  sensor_26  \\\n",
      "0  -0.956591  -0.972401   5.956213  ...  -7.026436  -6.006282  -6.005836   \n",
      "1  26.972724  -8.900861  -5.968298  ...  -1.996714  -7.933806  -3.136773   \n",
      "2 -21.069954 -15.933212  -9.016039  ...  -6.889685  54.052330  -6.109238   \n",
      "3 -29.073369   0.200774  -1.043742  ...  -2.126170  -1.035526   2.178769   \n",
      "4 -21.962423 -11.950189 -20.933785  ...  -2.051761  10.917567   1.905335   \n",
      "\n",
      "   sensor_27  sensor_28  sensor_29  sensor_30  sensor_31  sensor_32  target  \n",
      "0   7.043084  21.884650  -3.064152  -5.247552  -6.026107 -11.990822       1  \n",
      "1   8.774211  10.944759   9.858186  -0.969241  -3.935553 -15.892421       1  \n",
      "2  12.154595   6.095989 -40.195088  -3.958124  -8.079537  -5.160090       0  \n",
      "3  10.032723  -1.010897  -3.912848  -2.980338 -12.983597  -3.001077       1  \n",
      "4 -13.004707  17.169552   2.105194   3.967986  11.861657 -27.088846       2  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"C:/Users/choij/Desktop/datasets/hand_gesture_data/train.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/choij/Desktop/datasets/hand_gesture_data/test.csv\")\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape) # train 데이터보다 test 데이터가 더 많음을 알 수 있다.\n",
    "print(train_data.head()) # 34개의 feature 가지고 있음을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4213b19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD5CAYAAADLL+UrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOfklEQVR4nO3df6zddX3H8efLVrGInTAujLXdykyzrbCI4waZZosZJlTdbJeNrAtKXdiaEXRumRrYDzGLzUx0ZmMbJI1sLZkZVnSjMWEbqZK5jcAugqmlMBqbQaWDq4nINMGB7/1xPurZ7bm9p3h77oXP85F8c77n/f18vufzvfnmdb79nHO+TVUhSerDi5Z6AJKkyTH0Jakjhr4kdcTQl6SOGPqS1JGVSz2AhZx55pm1fv36pR6GJD2v3HvvvV+pqqm59WUf+uvXr2dmZmaphyFJzytJ/mtU3ekdSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyLL/Ra70QvbIH//UUg9By9CPvG//Sdu3V/qS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JGxQj/J7yY5kOSLSf4uyUuTnJHkjiQPt8fTh9pfm+RQkoeSXDpUvzDJ/rbt+iQ5GQclSRptwdBPsgb4bWC6qs4HVgBbgWuAfVW1AdjXnpNkY9t+HrAJuCHJira7G4HtwIa2bFrUo5EkHde40zsrgVVJVgKnAo8Bm4HdbftuYEtb3wzcUlVPV9Vh4BBwUZJzgNVVdVdVFXDzUB9J0gQsGPpV9WXgw8AjwFHgyar6Z+Dsqjra2hwFzmpd1gCPDu3iSKutaetz65KkCRlneud0Blfv5wI/DLwsyVuP12VErY5TH/Wa25PMJJmZnZ1daIiSpDGNM73zBuBwVc1W1f8CnwJeCzzepmxoj0+09keAdUP91zKYDjrS1ufWj1FVO6tquqqmp6amTuR4JEnHMU7oPwJcnOTU9m2bS4CDwF5gW2uzDbitre8FtiY5Jcm5DD6wvadNAT2V5OK2nyuG+kiSJmDlQg2q6u4ktwKfB54B7gN2AqcBe5JcyeCN4bLW/kCSPcADrf3VVfVs291VwC5gFXB7WyRJE7Jg6ANU1XXAdXPKTzO46h/VfgewY0R9Bjj/BMcoSVok/iJXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0ZK/STvCLJrUkeTHIwyc8kOSPJHUkebo+nD7W/NsmhJA8luXSofmGS/W3b9UlyMg5KkjTauFf6fw78Y1X9BPAq4CBwDbCvqjYA+9pzkmwEtgLnAZuAG5KsaPu5EdgObGjLpkU6DknSGBYM/SSrgZ8DbgKoqm9V1deAzcDu1mw3sKWtbwZuqaqnq+owcAi4KMk5wOqququqCrh5qI8kaQLGudL/MWAW+Jsk9yX5aJKXAWdX1VGA9nhWa78GeHSo/5FWW9PW59aPkWR7kpkkM7Ozsyd0QJKk+Y0T+iuBnwZurKpXA9+gTeXMY9Q8fR2nfmyxamdVTVfV9NTU1BhDlCSNY5zQPwIcqaq72/NbGbwJPN6mbGiPTwy1XzfUfy3wWKuvHVGXJE3IgqFfVf8NPJrkx1vpEuABYC+wrdW2Abe19b3A1iSnJDmXwQe297QpoKeSXNy+tXPFUB9J0gSsHLPdO4GPJXkJ8CXg1xm8YexJciXwCHAZQFUdSLKHwRvDM8DVVfVs289VwC5gFXB7WyRJEzJW6FfV/cD0iE2XzNN+B7BjRH0GOP8ExidJWkT+IleSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerI2KGfZEWS+5J8uj0/I8kdSR5uj6cPtb02yaEkDyW5dKh+YZL9bdv1SbK4hyNJOp4TudJ/F3Bw6Pk1wL6q2gDsa89JshHYCpwHbAJuSLKi9bkR2A5saMum72v0kqQTMlboJ1kLvBn46FB5M7C7re8GtgzVb6mqp6vqMHAIuCjJOcDqqrqrqgq4eaiPJGkCxr3S/zPgvcC3h2pnV9VRgPZ4VquvAR4danek1da09bn1YyTZnmQmyczs7OyYQ5QkLWTB0E/yC8ATVXXvmPscNU9fx6kfW6zaWVXTVTU9NTU15stKkhaycow2rwPekuRNwEuB1Un+Fng8yTlVdbRN3TzR2h8B1g31Xws81uprR9QlSROy4JV+VV1bVWuraj2DD2g/U1VvBfYC21qzbcBtbX0vsDXJKUnOZfCB7T1tCuipJBe3b+1cMdRHkjQB41zpz+eDwJ4kVwKPAJcBVNWBJHuAB4BngKur6tnW5ypgF7AKuL0tkqQJOaHQr6o7gTvb+leBS+ZptwPYMaI+A5x/ooOUJC0Of5ErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHVi71AE62C99z81IPQcvQvR+6YqmHIC0Jr/QlqSOGviR1xNCXpI4sGPpJ1iX5bJKDSQ4keVern5HkjiQPt8fTh/pcm+RQkoeSXDpUvzDJ/rbt+iQ5OYclSRplnCv9Z4Dfq6qfBC4Grk6yEbgG2FdVG4B97Tlt21bgPGATcEOSFW1fNwLbgQ1t2bSIxyJJWsCCoV9VR6vq8239KeAgsAbYDOxuzXYDW9r6ZuCWqnq6qg4Dh4CLkpwDrK6qu6qqgJuH+kiSJuCE5vSTrAdeDdwNnF1VR2HwxgCc1ZqtAR4d6nak1da09bl1SdKEjB36SU4DPgn8TlV9/XhNR9TqOPVRr7U9yUySmdnZ2XGHKElawFihn+TFDAL/Y1X1qVZ+vE3Z0B6faPUjwLqh7muBx1p97Yj6MapqZ1VNV9X01NTUuMciSVrAON/eCXATcLCqPjK0aS+wra1vA24bqm9NckqScxl8YHtPmwJ6KsnFbZ9XDPWRJE3AOLdheB3wNmB/kvtb7feBDwJ7klwJPAJcBlBVB5LsAR5g8M2fq6vq2dbvKmAXsAq4vS2SpAlZMPSr6l8ZPR8PcMk8fXYAO0bUZ4DzT2SAkqTF4y9yJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRiYd+kk1JHkpyKMk1k359SerZREM/yQrgr4A3AhuBX0uycZJjkKSeTfpK/yLgUFV9qaq+BdwCbJ7wGCSpWysn/HprgEeHnh8BXjO3UZLtwPb29H+SPDSBsfXgTOArSz2I5SAf3rbUQ9CxPD+/47osxl5+dFRx0qE/6kjqmELVTmDnyR9OX5LMVNX0Uo9DGsXzczImPb1zBFg39Hwt8NiExyBJ3Zp06P8HsCHJuUleAmwF9k54DJLUrYlO71TVM0neAfwTsAL466o6MMkxdM4pMy1nnp8TkKpjptQlSS9Q/iJXkjpi6EtSRwx9SeqIob9MJXl/kncfZ/uW53oLi+faN8lbvF+Shi3H87T1vSDJm55L3xc6Q//5awuD+xctat8k836jq6r2VtUHn+Nrqk9bOAnn6RguAAz9Efz2zjKS5A+AKxjcqmIWuBd4ksEtKV4CHALexuCE/nTb9iTwy8DPz21XVd8c8RqvHdH3JuDfgdcx+N3EfwJ/2Pb1VeDyqno8yduB6ap6R5JdwNeBaeCHgPdW1a2L+ffQ8rSE5ykMbtg4BXwT+M2qejDJZcB1wLOt7RvavlcBXwb+pKo+vph/g+e1qnJZBgtwIbAfOBVYzeCkfTfwg0NtPgC8s63vAn5laNvIdvO81ty+dwI3DD0/ne9dEPwG8Kdt/e3AXw7t4xMM/rW4kcGN9Jb87+hycpclPk/3ARva+muAz7T1/cCatv6K9vjdc9Xl/y+TvveO5vezwN9Xu+pJ8p1fKp+f5APAK4DTGPywbZRx281n+EpoLfDxJOcwuCI7PE+ff6iqbwMPJDn7BF9Pz09Lcp4mOQ14LfCJ5Lu38DqlPf4bsCvJHuBTJ3IwPTL0l5dRc227gC1V9YU2vfL6efqO224+3xha/wvgI1W1N8nrgffP0+fpofVFuS2gnheW4jx9EfC1qrrgmMFU/VaS1wBvBu5PckwbfY8f5C4f/wL8UpJVSV4O/GKrvxw4muTFwOVD7Z9q21ig3Shz+871AwzmQgG8B7GGLcl5WlVfBw63+Xsy8Kq2/sqquruq3sfg1szrRryuGkN/maiqzzOYYrkf+CTwubbpj4C7gTuAB4e63AK8J8l9SV55nHajzO071/sZ/DP6c3h/cw1Z4vP0cuDKJF8ADvC9/4DpQ0n2J/kigzelLwCfBTYmuT/Jr34/x/xC47d3JKkjXulLUkf8IPcFrH2f+rI55U9U1Y6lGI80iufpZDm9I0kdcXpHkjpi6EtSRwx9SeqIoS9JHfk/js9+fKBi2iEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['data_train', 'data_test']\n",
    "y = [train_data.shape[0], test_data.shape[0]]\n",
    "plot = sns.barplot(x=x,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42bb18d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             1.000000\n",
      "sensor_1     -94.746969\n",
      "sensor_2     -63.942094\n",
      "sensor_3    -122.195138\n",
      "sensor_4    -111.870691\n",
      "sensor_5     -94.147972\n",
      "sensor_6     -70.916786\n",
      "sensor_7    -105.956553\n",
      "sensor_8    -102.965354\n",
      "sensor_9     -81.268085\n",
      "sensor_10    -47.937561\n",
      "sensor_11   -115.943693\n",
      "sensor_12   -102.916207\n",
      "sensor_13   -115.053373\n",
      "sensor_14    -59.689434\n",
      "sensor_15   -107.985386\n",
      "sensor_16   -126.950747\n",
      "sensor_17    -95.956853\n",
      "sensor_18    -83.854213\n",
      "sensor_19   -108.964270\n",
      "sensor_20   -108.094304\n",
      "sensor_21   -103.876936\n",
      "sensor_22    -59.993001\n",
      "sensor_23    -93.171275\n",
      "sensor_24   -127.797649\n",
      "sensor_25    -99.115177\n",
      "sensor_26    -86.193378\n",
      "sensor_27   -105.751637\n",
      "sensor_28   -105.890010\n",
      "sensor_29    -74.977182\n",
      "sensor_30    -74.006065\n",
      "sensor_31   -121.097086\n",
      "sensor_32   -123.876153\n",
      "target         0.000000\n",
      "dtype: float64\n",
      "id           2335.000000\n",
      "sensor_1       68.876142\n",
      "sensor_2       39.913391\n",
      "sensor_3      127.124171\n",
      "sensor_4      102.015561\n",
      "sensor_5       89.059852\n",
      "sensor_6       34.923040\n",
      "sensor_7      120.046277\n",
      "sensor_8      125.160611\n",
      "sensor_9       74.101715\n",
      "sensor_10      47.030119\n",
      "sensor_11     127.110419\n",
      "sensor_12      99.932331\n",
      "sensor_13     107.910041\n",
      "sensor_14      40.026878\n",
      "sensor_15     126.981907\n",
      "sensor_16     120.974880\n",
      "sensor_17      85.952050\n",
      "sensor_18      39.993408\n",
      "sensor_19     117.934200\n",
      "sensor_20     121.026042\n",
      "sensor_21     102.882569\n",
      "sensor_22      40.917741\n",
      "sensor_23     121.959404\n",
      "sensor_24     127.161055\n",
      "sensor_25      58.113657\n",
      "sensor_26      59.105536\n",
      "sensor_27     123.179253\n",
      "sensor_28     111.137925\n",
      "sensor_29      54.098746\n",
      "sensor_30      35.896503\n",
      "sensor_31     125.974107\n",
      "sensor_32     104.959621\n",
      "target          3.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.min())\n",
    "print(train_data.max()) #범위가 -127 ~ 127 이름을 알 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6ab41",
   "metadata": {},
   "source": [
    "**input 값에 음수 포함되면 relu 함수를 활성화 함수로 쓸경우 backpropagation 과정에서 기울기가 0이므로 0~1 사이가 되게 정규화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d250aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2335, 8, 4, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_data.drop(['target', 'id'], axis = 1) #불필요한 특징 제거\n",
    "train_x = (train_x + 130) / 260   # 130으로 나누는게 아니라 범위가 -130~ 130 이므로 260으로 나눈다.\n",
    "train_x = np.array(train_x) # 행렬로 만들어준다.\n",
    "train_x = train_x.reshape(-1,8,4,1)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a78915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2335,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_data['target']\n",
    "train_y = np.array(train_y)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76cde8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9343, 8, 4, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = test_data.drop('id', axis = 1)\n",
    "x_test = (x_test + 130) / 260\n",
    "x_test = np.array(x_test)\n",
    "x_test = x_test.reshape(-1,8,4,1)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6533e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min :  0.008470580769230742 max : 0.9890809815384616\n"
     ]
    }
   ],
   "source": [
    "print('min : ', train_x.min(), 'max :', train_x.max()) #정규화 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf89037",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3329091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, filters, kernel_size):\n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters, (1,1), padding = 'SAME')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters, kernel_size, padding = 'SAME')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters * 4, (1,1), padding = 'SAME')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    \n",
    "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "811e6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, filters, kernel_size):\n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters, (1,1), padding = 'SAME')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters, kernel_size, padding = 'SAME')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters * 4, (1,1), padding = 'SAME')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    \n",
    "    X_shortcut = tf.keras.layers.Conv2D(filters * 4, (1,1), padding = 'SAME')(X_shortcut)\n",
    "    X_shortcut = tf.keras.layers.BatchNormalization()(X_shortcut)\n",
    "    \n",
    "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92d0f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomModel(input_shape = (8,4,1), classes = 4):\n",
    "    X_input = tf.keras.layers.Input(input_shape)\n",
    "    X = X_input\n",
    "    \n",
    "    X = convolutional_block(X, 128, (3,2))\n",
    "    X = identity_block(X, 128, (3,2))\n",
    "    X = identity_block(X, 128, (3,2))\n",
    "    \n",
    "    X = tf.keras.layers.AveragePooling2D(2,2)(X)\n",
    "    \n",
    "    X = convolutional_block(X, 256, (2,1))\n",
    "    X = identity_block(X, 256, (2,1))\n",
    "    X = identity_block(X, 256, (2,1))\n",
    "    \n",
    "    X = tf.keras.layers.GlobalAveragePooling2D()(X)\n",
    "    \n",
    "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    \n",
    "    X = tf.keras.layers.Dense(classes, activation = 'softmax')(X)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = X_input, outputs = X, name = 'CustomModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90e73e38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 / val_accuracy : 0.8974/ val_loss : 0.3102\n",
      "fold 2 / val_accuracy : 0.8910/ val_loss : 0.5826\n",
      "fold 3 / val_accuracy : 0.8846/ val_loss : 0.6496\n",
      "fold 4 / val_accuracy : 0.9103/ val_loss : 0.3687\n",
      "fold 5 / val_accuracy : 0.9231/ val_loss : 0.3758\n",
      "fold 6 / val_accuracy : 0.8782/ val_loss : 0.4873\n",
      "fold 7 / val_accuracy : 0.8846/ val_loss : 0.4357\n",
      "fold 8 / val_accuracy : 0.8846/ val_loss : 0.4911\n",
      "fold 9 / val_accuracy : 0.8974/ val_loss : 0.9634\n",
      "fold 10 / val_accuracy : 0.9038/ val_loss : 0.6061\n",
      "fold 11 / val_accuracy : 0.8516/ val_loss : 0.7058\n",
      "fold 12 / val_accuracy : 0.8774/ val_loss : 0.5539\n",
      "fold 13 / val_accuracy : 0.8774/ val_loss : 0.5066\n",
      "fold 14 / val_accuracy : 0.9161/ val_loss : 0.3663\n",
      "fold 15 / val_accuracy : 0.9097/ val_loss : 0.4213\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 15, random_state = 42, shuffle = True)\n",
    "n = 0\n",
    "\n",
    "cnn_pred = []\n",
    "\n",
    "for train_index, valid_index in skf.split(train_x, train_y):\n",
    "    n+= 1\n",
    "    x_train, x_valid = train_x[train_index], train_x[valid_index]\n",
    "    y_train, y_valid = train_y[train_index], train_y[valid_index]\n",
    "    \n",
    "    x_train_mix = np.array(x_train)\n",
    "    for x in range(x_train_mix.shape[0]):\n",
    "        for i in range(5):\n",
    "            y = np.random.randint(0,8)\n",
    "            z = np.random.randint(0,4)\n",
    "            \n",
    "            while True:\n",
    "                c = np.random.randint(0, x_train_mix.shape[0] - 1)\n",
    "                if ((x != c)and (y_train[x] == y_train[c])):\n",
    "                    break\n",
    "            \n",
    "            x_train_mix[x][y][z] = x_train[c][y][z]\n",
    "            \n",
    "    x_train = np.append(x_train, x_train_mix, axis = 0)\n",
    "    y_train = np.append(y_train, y_train, axis = 0)\n",
    "    \n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state = 42)\n",
    "    \n",
    "    y_train = tf.one_hot(y_train,4)\n",
    "    y_train = tf.reshape(y_train, [-1,4])\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    y_valid = tf.one_hot(y_valid, 4)\n",
    "    y_valid = tf.reshape(y_valid, [-1,4])\n",
    "    y_valid = np.array(y_valid)\n",
    "    \n",
    "    model = CustomModel()\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                     loss = 'categorical_crossentropy',\n",
    "                     metrics = ['accuracy'])\n",
    "    filename = 'CNN_checkpoint.h5'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filename,\n",
    "                                                   monitor = 'val_accuracy',\n",
    "                                                   verbose = 0,\n",
    "                                                   save_best_only = True,\n",
    "                                                   mode = 'auto')\n",
    "    \n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
    "                                                    patience = 12)\n",
    "    \n",
    "    reduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor = 'val_accuracy',\n",
    "        factoer = 0.5,\n",
    "        patience = 6)\n",
    "    \n",
    "    data = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_data = (x_valid, y_valid),\n",
    "                     epochs = 60,\n",
    "                     batch_size  = 32,\n",
    "                    callbacks = [reduceLR, earlystopping, checkpoint],\n",
    "                    verbose = 0)\n",
    "    \n",
    "    idx = data.history['val_accuracy'].index(max(data.history['val_accuracy']))\n",
    "    \n",
    "    print('fold %d / val_accuracy : %0.4f/ val_loss : %0.4f'% (n,\n",
    "                                                              data.history['val_accuracy'][idx],\n",
    "                                                              data.history['val_loss'][idx]))\n",
    "    \n",
    "    model = tf.keras.models.load_model('C:/Users/choij/CNN_checkpoint.h5')\n",
    "    pred_proba = model.predict(x_test)\n",
    "    cnn_pred.append(pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "664ecd4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9938905e-01 3.1459692e-04 4.6534002e-05 2.4978112e-04]\n",
      "[9.9995005e-01 2.5944717e-06 4.3694661e-05 3.5639300e-06]\n",
      "[9.9303114e-01 6.4951082e-04 4.5329304e-03 1.7863380e-03]\n",
      "[9.99906778e-01 2.54512884e-06 7.60933399e-05 1.46274315e-05]\n",
      "[9.9996221e-01 5.3163177e-07 2.9620596e-05 7.7370150e-06]\n",
      "[9.9997008e-01 1.6133588e-05 9.8773526e-06 3.8752455e-06]\n",
      "[0.9958643  0.00191162 0.00104367 0.00118041]\n",
      "[9.9993479e-01 3.2554584e-05 2.4628953e-05 7.9437177e-06]\n",
      "[9.9997723e-01 2.0316766e-06 2.7538435e-06 1.7982285e-05]\n",
      "[9.8960763e-01 3.0334189e-04 1.0036705e-02 5.2373482e-05]\n",
      "[9.9999774e-01 1.2937104e-08 2.2831221e-06 2.5584288e-08]\n",
      "[9.9670249e-01 3.6048406e-04 2.2718280e-03 6.6518469e-04]\n",
      "[9.9991143e-01 3.6345104e-05 3.6828205e-05 1.5366608e-05]\n",
      "[9.9996424e-01 4.1315352e-06 1.1395786e-06 3.0450858e-05]\n",
      "[9.9949121e-01 1.2884602e-04 1.1973710e-04 2.6014357e-04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = cnn_pred[0]\n",
    "pred_proba = np.array(pred_proba)\n",
    "print(pred_proba[0])\n",
    "\n",
    "for x in range(1,15):\n",
    "    pred_proba += cnn_pred[x]\n",
    "    print(cnn_pred[x][0])\n",
    "\n",
    "pred_class = []\n",
    "\n",
    "for i in pred_proba:\n",
    "    pred = np.argmax(i)\n",
    "    pred_class.append(pred)\n",
    "    \n",
    "pred_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
